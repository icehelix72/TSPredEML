{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icehelix72/TSPredEML/blob/main/Monthly_Rason_Data_Downloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VRzUJ9HJYNW"
      },
      "source": [
        "Author: Achmed Gerland\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSzzi4N_4hrc",
        "outputId": "3cfc5648-3a3b-42c6-da3e-35b40ce73778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting siphon\n",
            "  Downloading siphon-0.10.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (2.9.0.post0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from siphon) (4.13.4)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.11/dist-packages (from siphon) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from siphon) (5.29.4)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from datetime) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil) (1.17.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9.1->siphon) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9.1->siphon) (4.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface->datetime) (75.2.0)\n",
            "Downloading siphon-0.10.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, datetime, siphon\n",
            "Successfully installed datetime-5.5 siphon-0.10.0 zope.interface-7.2\n"
          ]
        }
      ],
      "source": [
        "#Install terlebih dahulu library yang dibutuhkan\n",
        "!pip install siphon datetime python-dateutil pandas requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUujXTYV2YcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be30096-861d-4e3c-fffd-84f78446c4b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Lakukan mount drive terlebih dahulu untuk menyimpan file spreadsheet di google drive\n",
        "#Jalankan skrip ini sekali saja\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2o9HIDC4Tq0"
      },
      "outputs": [],
      "source": [
        "#Impor library yang akan digunakan\n",
        "from datetime import datetime, timedelta\n",
        "from siphon.simplewebservice.wyoming import WyomingUpperAir\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import pandas as pd\n",
        "from requests import HTTPError\n",
        "import sys\n",
        "import time\n",
        "\n",
        "#Fungsi untuk membuat list tanggal dan waktu dengan interval jam tertentu pada suatu bulan\n",
        "def generate_dates(year, month, interval_hours):\n",
        "    start_date = datetime(year, month, 1)\n",
        "    end_date = start_date + relativedelta(months=1)\n",
        "\n",
        "    current_date = start_date\n",
        "    dates = []\n",
        "\n",
        "    while current_date < end_date:\n",
        "        dates.append(current_date)\n",
        "        current_date += timedelta(hours=interval_hours)\n",
        "\n",
        "    return dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czpUBfgb4Tq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36d3eac-eff1-4744-a099-83c1806afd96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tahun: 2023\n",
            "Bulan (dalam angka 1-12): 12\n"
          ]
        }
      ],
      "source": [
        "year = int(input(\"Tahun: \")) #Mengambil masukan tahun sebagai integer\n",
        "month = int(input(\"Bulan (dalam angka 1-12): \")) #Mengambil masukan bulan sebagai integer\n",
        "dates = generate_dates(year, month, 12) #Membuat list tanggal dan waktu\n",
        "station_icao = \"WIII\" #input(\"Kode ICAO Stasiun (lihat di web Wyoming): \") #Mengambil masukan kode ICAO stasiun yang hendak dicari\n",
        "#Kode ICAO tidak sama dengan kode stasiun yang berupa angka. Untuk lebih jelasnya, silahkan lihat kode ICAO yang ada di web Wyoming"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "max_retries = 10  # Set the maximum number of retries\n",
        "retry_delay = 30 # Set the delay in seconds before retrying\n",
        "\n",
        "retries = 0\n",
        "while retries < max_retries:\n",
        "    try:\n",
        "        print(f\"Attempt {retries + 1} of {max_retries}...\")\n",
        "\n",
        "        # Membuat dictionary untuk memasukkan dataframe dari data radiosonde 12 jam-an\n",
        "        rason_data = {}\n",
        "        http_error_occurred_in_attempt = False # Flag to track if HTTPError occurs in this attempt\n",
        "\n",
        "        # Mengambil data radiosonde dari library siphon berdasaran waktu dan stasiun\n",
        "        for date in dates:\n",
        "            print(\"Memproses data tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "            try:\n",
        "                rason_data[date.strftime(r'%Y-%m-%d %HZ')] = df = WyomingUpperAir.request_data(date, station_icao)\n",
        "            except KeyError:\n",
        "                print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "            except ValueError:\n",
        "                print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "            except IndexError:\n",
        "                print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "            except HTTPError:\n",
        "                print(\"HTTPError: Server sedang sibuk, mencoba lagi...\")\n",
        "                http_error_occurred_in_attempt = True # Set flag\n",
        "                break # Break the inner for loop to trigger a retry attempt\n",
        "\n",
        "        # Mengecek apakah HTTPError terjadi pada percobaan ini.\n",
        "        # Jika tidak, keluar dari retry loop (terlepas dari apakah semua data terkumpul).\n",
        "        if not http_error_occurred_in_attempt:\n",
        "            print(\"No HTTPError occurred in this attempt.\")\n",
        "            break # Exit the retry loop if no HTTPError was encountered\n",
        "\n",
        "    except Exception as e:\n",
        "        # This catches any other exceptions during the process that were not caught inside the inner loop.\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        # You might want to decide if other exceptions should also trigger a retry or stop the program.\n",
        "        # For now, they will increment retries and potentially retry.\n",
        "\n",
        "    # Increment retries and sleep if an HTTPError occurred or another unexpected exception occurred\n",
        "    retries += 1\n",
        "    if retries < max_retries and http_error_occurred_in_attempt: # Only sleep and retry if HTTPError occurred\n",
        "        print(f\"Retrying in {retry_delay} seconds...\")\n",
        "        time.sleep(retry_delay)\n",
        "    elif retries < max_retries and not http_error_occurred_in_attempt:\n",
        "         # If no HTTPError and not all data collected, maybe you still want to retry for other errors?\n",
        "         # Or just stop? The current logic stops if no HTTPError occurred.\n",
        "         pass # No sleep if we are breaking the loop anyway\n",
        "\n",
        "# After the loop\n",
        "if not http_error_occurred_in_attempt:\n",
        "    print(\"Process completed without HTTP errors.\")\n",
        "    if len(rason_data.items()) == len(dates):\n",
        "        print(\"Data collection completed successfully.\")\n",
        "    else:\n",
        "        print(\"Data collection was incomplete (possibly due to other errors like KeyError).\")\n",
        "        collected_dates = [datetime.strptime(d_str, r'%Y-%m-%d %HZ') for d_str in rason_data.keys()]\n",
        "        missing_dates = [d for d in dates if d not in collected_dates]\n",
        "        print(f\"Missing data for dates: {[d.strftime(r'%Y-%m-%d %HZ') for d in missing_dates]}\")\n",
        "else:\n",
        "     # This part is reached if max_retries were reached due to persistent HTTP errors\n",
        "     print(\"Maximum retries reached due to persistent HTTP errors. Data collection was incomplete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4eQsSr6yCvv",
        "outputId": "bae2d938-72e9-4c5e-9f0a-e21c49cdc5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempt 1 of 10...\n",
            "Memproses data tanggal 2023-12-01 00Z\n",
            "Memproses data tanggal 2023-12-01 12Z\n",
            "Memproses data tanggal 2023-12-02 00Z\n",
            "Memproses data tanggal 2023-12-02 12Z\n",
            "Memproses data tanggal 2023-12-03 00Z\n",
            "Memproses data tanggal 2023-12-03 12Z\n",
            "Memproses data tanggal 2023-12-04 00Z\n",
            "Memproses data tanggal 2023-12-04 12Z\n",
            "Memproses data tanggal 2023-12-05 00Z\n",
            "Memproses data tanggal 2023-12-05 12Z\n",
            "Memproses data tanggal 2023-12-06 00Z\n",
            "Memproses data tanggal 2023-12-06 12Z\n",
            "Memproses data tanggal 2023-12-07 00Z\n",
            "Memproses data tanggal 2023-12-07 12Z\n",
            "Memproses data tanggal 2023-12-08 00Z\n",
            "Memproses data tanggal 2023-12-08 12Z\n",
            "Memproses data tanggal 2023-12-09 00Z\n",
            "Memproses data tanggal 2023-12-09 12Z\n",
            "Memproses data tanggal 2023-12-10 00Z\n",
            "Memproses data tanggal 2023-12-10 12Z\n",
            "Memproses data tanggal 2023-12-11 00Z\n",
            "Memproses data tanggal 2023-12-11 12Z\n",
            "Memproses data tanggal 2023-12-12 00Z\n",
            "Memproses data tanggal 2023-12-12 12Z\n",
            "Memproses data tanggal 2023-12-13 00Z\n",
            "Memproses data tanggal 2023-12-13 12Z\n",
            "Memproses data tanggal 2023-12-14 00Z\n",
            "Memproses data tanggal 2023-12-14 12Z\n",
            "Memproses data tanggal 2023-12-15 00Z\n",
            "Memproses data tanggal 2023-12-15 12Z\n",
            "Memproses data tanggal 2023-12-16 00Z\n",
            "Memproses data tanggal 2023-12-16 12Z\n",
            "Memproses data tanggal 2023-12-17 00Z\n",
            "Memproses data tanggal 2023-12-17 12Z\n",
            "Memproses data tanggal 2023-12-18 00Z\n",
            "Memproses data tanggal 2023-12-18 12Z\n",
            "Memproses data tanggal 2023-12-19 00Z\n",
            "Memproses data tanggal 2023-12-19 12Z\n",
            "Memproses data tanggal 2023-12-20 00Z\n",
            "Memproses data tanggal 2023-12-20 12Z\n",
            "Memproses data tanggal 2023-12-21 00Z\n",
            "Memproses data tanggal 2023-12-21 12Z\n",
            "Memproses data tanggal 2023-12-22 00Z\n",
            "Memproses data tanggal 2023-12-22 12Z\n",
            "Data tidak tersedia untuk pengamatan tanggal 2023-12-22 12Z\n",
            "Memproses data tanggal 2023-12-23 00Z\n",
            "Memproses data tanggal 2023-12-23 12Z\n",
            "Memproses data tanggal 2023-12-24 00Z\n",
            "Memproses data tanggal 2023-12-24 12Z\n",
            "Memproses data tanggal 2023-12-25 00Z\n",
            "Memproses data tanggal 2023-12-25 12Z\n",
            "Memproses data tanggal 2023-12-26 00Z\n",
            "Memproses data tanggal 2023-12-26 12Z\n",
            "Memproses data tanggal 2023-12-27 00Z\n",
            "Memproses data tanggal 2023-12-27 12Z\n",
            "Memproses data tanggal 2023-12-28 00Z\n",
            "Memproses data tanggal 2023-12-28 12Z\n",
            "Memproses data tanggal 2023-12-29 00Z\n",
            "Memproses data tanggal 2023-12-29 12Z\n",
            "Memproses data tanggal 2023-12-30 00Z\n",
            "Memproses data tanggal 2023-12-30 12Z\n",
            "Memproses data tanggal 2023-12-31 00Z\n",
            "Memproses data tanggal 2023-12-31 12Z\n",
            "No HTTPError occurred in this attempt.\n",
            "Process completed without HTTP errors.\n",
            "Data collection was incomplete (possibly due to other errors like KeyError).\n",
            "Missing data for dates: ['2023-12-22 12Z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPwFa4e44Tq4"
      },
      "outputs": [],
      "source": [
        "#Untuk mengeluarkan file data yang tanggalnya dipisahkan per-sheet\n",
        "#Keluarkan file spreadsheet yang berisi semua dataframe yang ada di dictionary\n",
        "with pd.ExcelWriter(r\"/content/drive/MyDrive/Skripsi/WIII/\"+str(year)+\"/\"+station_icao+str(month).zfill(2)+str(year)+\".xlsx\") as writer:\n",
        "    for sheet_name, df in rason_data.items():\n",
        "        #Jika hendak mem-filter data untuk per tekanan, gunakan baris kode di bawah ini (hapus tanda # pada baris kode di bawah ini)\n",
        "        #df = df.loc[(df.index == 0) | (df.pressure.isin([850, 700, 500, 300, 200, 150, 100, 50, 30]))]\n",
        "        df['depression'] = df['temperature'] - df['dewpoint']\n",
        "        df = df[['time', 'pressure', 'height', 'temperature', 'dewpoint', 'depression', 'direction', 'speed', 'u_wind', 'v_wind', 'station', 'station_number', 'latitude', 'longitude', 'elevation', 'pw']]\n",
        "        df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i62Fr4vWcKee"
      },
      "outputs": [],
      "source": [
        "# Jangan jalankan sel ini!\n",
        "# Gunakan ini untuk soal UTS\n",
        "#with pd.ExcelWriter(r\"/content/drive/MyDrive/Test2.xlsx\") as writer:\n",
        "     #df_dates = []\n",
        "     #for i in rason_data.keys():\n",
        "          #temp_df = rason_data[i]\n",
        "          #df_dates.append(temp_df)\n",
        "     #rason_data['merged'] = pd.concat(df_dates)\n",
        "     #df= rason_data['merged']\n",
        "     #df = df.loc[(df.index == 0) | (df.pressure.isin([850, 700, 500, 300, 200, 150, 100, 50, 30]))]\n",
        "     #df['depression'] = df['temperature'] - df['dewpoint']\n",
        "     #df = df[['time', 'pressure', 'height', 'temperature', 'dewpoint', 'depression', 'direction', 'speed', 'u_wind', 'v_wind', 'station', 'station_number', 'latitude', 'longitude', 'elevation', 'pw']]\n",
        "     #df.to_excel(writer, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k09dVpmK4Tq4"
      },
      "outputs": [],
      "source": [
        "#Membuat dictionary untuk memasukkan dataframe dari data radiosonde 12 jam-an\n",
        "rason_data = {}\n",
        "\n",
        "#Mengambil data radiosonde dari library siphon berdasaran waktu dan stasiun\n",
        "for date in dates:\n",
        "  print(\"Memproses data tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "  try:\n",
        "    rason_data[date.strftime(r'%Y-%m-%d %HZ')] = df = WyomingUpperAir.request_data(date, station_icao)\n",
        "  except KeyError:\n",
        "    print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "  except ValueError:\n",
        "    print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "  except IndexError:\n",
        "    print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "  except HTTPError:\n",
        "    raise SystemExit(\"Server sedang sibuk, jalankan ulang sel ini\")\n",
        "    break\n",
        "\n",
        "#Mengecek berapa apakah data pengamatan yang tersedia sudah lengkap selama sebulan\n",
        "if len(rason_data.items()) == len(dates):\n",
        "  print(\"\\nData pengamatan tersedia lengkap selama sebulan\")\n",
        "else:\n",
        "  print(\"\\nData pengamatan yang tersedia hanya %d dari %d\" % (len(rason_data.items()), len(dates)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "max_retries = 10  # Set the maximum number of retries\n",
        "retry_delay = 30 # Set the delay in seconds before retrying\n",
        "\n",
        "retries = 0\n",
        "while retries < max_retries:\n",
        "    try:\n",
        "        print(f\"Attempt {retries + 1} of {max_retries}...\")\n",
        "\n",
        "        #Membuat dictionary untuk memasukkan dataframe dari data radiosonde 12 jam-an\n",
        "        rason_data = {}\n",
        "\n",
        "        #Mengambil data radiosonde dari library siphon berdasaran waktu dan stasiun\n",
        "        for date in dates:\n",
        "          print(\"Memproses data tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          try:\n",
        "            rason_data[date.strftime(r'%Y-%m-%d %HZ')] = df = WyomingUpperAir.request_data(date, station_icao)\n",
        "          except KeyError:\n",
        "            print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          except ValueError:\n",
        "            print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          except IndexError:\n",
        "            print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          except HTTPError:\n",
        "            raise SystemExit(\"Server sedang sibuk, jalankan ulang sel ini\")\n",
        "            break\n",
        "\n",
        "        #Mengecek berapa apakah data pengamatan yang tersedia sudah lengkap selama sebulan\n",
        "        if len(rason_data.items()) == len(dates):\n",
        "          print(\"\\nData pengamatan tersedia lengkap selama sebulan\")\n",
        "        else:\n",
        "          print(\"\\nData pengamatan yang tersedia hanya %d dari %d\" % (len(rason_data.items()), len(dates)))\n",
        "\n",
        "        # If the code above runs without error, break the loop\n",
        "        print(\"Code executed successfully!\")\n",
        "        break\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        retries += 1\n",
        "        if retries < max_retries:\n",
        "            print(f\"Retrying in {retry_delay} seconds...\")\n",
        "            time.sleep(retry_delay)\n",
        "        else:\n",
        "            print(\"Maximum retries reached. Could not execute the code.\")"
      ],
      "metadata": {
        "id": "aienPJPutO2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "max_retries = 10  # Set the maximum number of retries\n",
        "retry_delay = 30 # Set the delay in seconds before retrying\n",
        "\n",
        "retries = 0\n",
        "while retries < max_retries:\n",
        "    try:\n",
        "        print(f\"Attempt {retries + 1} of {max_retries}...\")\n",
        "\n",
        "        #Membuat dictionary untuk memasukkan dataframe dari data radiosonde 12 jam-an\n",
        "        rason_data = {}\n",
        "\n",
        "        #Mengambil data radiosonde dari library siphon berdasaran waktu dan stasiun\n",
        "        for date in dates:\n",
        "          print(\"Memproses data tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          try:\n",
        "            rason_data[date.strftime(r'%Y-%m-%d %HZ')] = df = WyomingUpperAir.request_data(date, station_icao)\n",
        "          except KeyError:\n",
        "            print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          except ValueError:\n",
        "            print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          except IndexError:\n",
        "            print(\"Data tidak tersedia untuk pengamatan tanggal %s\" % (date.strftime(r'%Y-%m-%d %HZ')))\n",
        "          except HTTPError:\n",
        "            # Jangan raise SystemExit di sini, biarkan exception ini ditangkap oleh blok luar\n",
        "            # This allows the outer retry loop to handle the HTTPError\n",
        "            print(\"HTTPError: Server sedang sibuk, mencoba lagi...\")\n",
        "            # The `break` here will still exit the inner for loop but the outer\n",
        "            # while loop will continue if retries < max_retries\n",
        "            #break # Break the inner for loop to trigger a retry attempt for the whole set of dates\n",
        "\n",
        "\n",
        "        #Mengecek berapa apakah data pengamatan yang tersedia sudah lengkap selama sebulan\n",
        "        # This check might not be accurate if an HTTPError occurs and the inner loop breaks.\n",
        "        # Consider moving this check outside the retry loop or adjust it.\n",
        "        if len(rason_data.items()) == len(dates):\n",
        "          print(\"\\nData pengamatan tersedia lengkap selama sebulan\")\n",
        "        else:\n",
        "          print(\"\\nData pengamatan yang tersedia hanya %d dari %d\" % (len(rason_data.items()), len(dates)))\n",
        "          # If data is not complete, and no HTTPError occurred, you might want to break\n",
        "          # the retry loop here as well if you don't expect missing data otherwise.\n",
        "          # Or, you might want to retry in case the missing data was a temporary issue.\n",
        "          # For now, we assume you want to retry if an HTTPError caused incomplete data.\n",
        "\n",
        "\n",
        "        # If the code above runs without error AND collected all dates, break the retry loop\n",
        "        # If an HTTPError caused a break in the inner loop, rason_data might be incomplete,\n",
        "        # and the retry loop will continue.\n",
        "        if len(rason_data.items()) == len(dates):\n",
        "            print(\"Code executed successfully and all data collected!\")\n",
        "            break # Exit the retry loop if all data is successfully fetched\n",
        "\n",
        "    except Exception as e:\n",
        "        # This catches any other exceptions during the process, including\n",
        "        # the HTTPError if the inner break was removed.\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        retries += 1\n",
        "        if retries < max_retries:\n",
        "            print(f\"Retrying in {retry_delay} seconds...\")\n",
        "            time.sleep(retry_delay)\n",
        "        else:\n",
        "            print(\"Maximum retries reached. Could not execute the code.\")\n",
        "\n",
        "# After the loop, check if data was successfully retrieved\n",
        "if len(rason_data.items()) == len(dates):\n",
        "    print(\"Data collection completed successfully.\")\n",
        "else:\n",
        "    print(\"Data collection was incomplete after multiple retries.\")\n",
        "    # Handle incomplete data as needed, e.g., print which dates are missing\n",
        "    collected_dates = [datetime.strptime(d_str, r'%Y-%m-%d %HZ') for d_str in rason_data.keys()]\n",
        "    missing_dates = [d for d in dates if d not in collected_dates]\n",
        "    print(f\"Missing data for dates: {[d.strftime(r'%Y-%m-%d %HZ') for d in missing_dates]}\")"
      ],
      "metadata": {
        "id": "Sad1b1EkuVj8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}